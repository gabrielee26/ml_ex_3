{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Esercitazione 3 - Classificatori: Regressione Logistica e SVM**\n\nIn questa esercitazione applicheremo quanto appreso sui classificatori. Nello specifico utilizzeremo:\n\n* **Regressione Logistica:** Un modello lineare che utilizza la funzione sigmoide per predire le probabilità delle classi.\n\n* **Support Vector Machines (SVM):** Efficace sia per problemi lineari che non lineari utilizzando il kernel trick.","metadata":{}},{"cell_type":"markdown","source":"### **Dataset MNIST-784**\n\nIl dataset di riferimento sarà `MNIST-784`, già visto in precedenza. Il dataset contiene immagini di 10 classi (da 0 a 9). Per comodità utilizzeremo soltanto 2 classi inizialmente, per rendere la classificazione binaria. Nello specifico utilizzeremo soltanto le immagini che hanno come etichetta `3` e `8`. \n\nIl codice seguente esegui l' import delle librerie necessarie e la selezione delle etichette che ci interessano. Le etichette vengono anche rimpiazzate con `1` e `0`, emulando il caso di classificazione binaria.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.252100Z","iopub.status.idle":"2025-04-06T20:28:28.252591Z","shell.execute_reply":"2025-04-06T20:28:28.252363Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mnist = fetch_openml('mnist_784', version=1, parser='auto')\nX, y = mnist.data, mnist.target.astype(int)\n\nindexes = (y == 3) | (y == 8)\nX = X[indexes]  \ny = y[indexes]\n\ny = np.where(y == 8, 1, 0)\n\nprint(f\"Features shape: {X.shape}, Labels shape: {y.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:29:50.651899Z","iopub.execute_input":"2025-04-06T20:29:50.652330Z","iopub.status.idle":"2025-04-06T20:29:53.937279Z","shell.execute_reply.started":"2025-04-06T20:29:50.652300Z","shell.execute_reply":"2025-04-06T20:29:53.935420Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-70972273cb6f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_784'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mfetch_openml\u001b[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser)\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;34m\"both.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             )\n\u001b[0;32m--> 918\u001b[0;31m         data_info = _get_data_info_by_name(\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_get_data_info_by_name\u001b[0;34m(name, version, data_home, n_retries, delay)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_SEARCH_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/data_version/{}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         json_data = _get_json_content_from_openml_api(\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0merror_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_get_json_content_from_openml_api\u001b[0;34m(url, error_message, data_home, n_retries, delay)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# (e.g., data not found)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# 412 error, not in except for nicer traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_get_json_content_from_openml_api\u001b[0;34m(url, error_message, data_home, n_retries, delay)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# 412 is an OpenML specific error code, indicating a generic error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_load_json\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         with closing(\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0m_open_openml_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         ) as response:\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36m_open_openml_url\u001b[0;34m(openml_path, data_home, n_retries, delay)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTemporaryDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmpdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 with closing(\n\u001b[0;32m--> 163\u001b[0;31m                     _retry_on_network_error(n_retries, delay, req.full_url)(urlopen)(\n\u001b[0m\u001b[1;32m    164\u001b[0m                         \u001b[0mreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0;31m# 412 is a specific OpenML error code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Proxy Error"],"ename":"HTTPError","evalue":"HTTP Error 502: Proxy Error","output_type":"error"}],"execution_count":11},{"cell_type":"markdown","source":"### **Divisione e standardizzazione del dataset** \n\nDividiamo il dataset in `train set`, `validation set` e `test set` utilizzando le proporzioni già impostate. Successivamente applichiamo la standardizzazione utilizzando `StandardScaler`.","metadata":{}},{"cell_type":"code","source":"# Usare le seguenti proporzioni per il train, validation e test\ntrain_fraction = 0.6  \nvalidation_fraction = 0.2  \ntest_fraction = 0.2\n\n# svolgimento...\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_temp, y_train, y_temp = train_test_split(\n    X, y,\n    train_size=train_fraction,\n    random_state=42,\n    stratify=y\n)\n\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp,\n    test_size=0.5, \n    random_state=42,\n    stratify=y_temp\n)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)\n\nprint(\"Train set shape:\", X_train_scaled.shape)\nprint(\"Validation set shape:\", X_val_scaled.shape)\nprint(\"Test set shape:\", X_test_scaled.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:29:59.855705Z","iopub.execute_input":"2025-04-06T20:29:59.856124Z","iopub.status.idle":"2025-04-06T20:29:59.870126Z","shell.execute_reply.started":"2025-04-06T20:29:59.856093Z","shell.execute_reply":"2025-04-06T20:29:59.868559Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-ffb73b407c1a>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m X_train, X_temp, y_train, y_temp = train_test_split(\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_fraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"],"ename":"NameError","evalue":"name 'X' is not defined","output_type":"error"}],"execution_count":13},{"cell_type":"markdown","source":"## **Esercizio 1: Implementare la Regressione Logistica**\n\nPer implementare la regressione logistica utilizzeremo la classe `sklearn.linear_model.LogisticRegression` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n\nPer utilizzarla al meglio, di seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell' istanza:\n\n* **`C`**: Inverso della forza di regolarizzazione L2 (λ). Valori più piccoli indicano una regolarizzazione più forte.\n* **`solver`**: Algoritmo da utilizzare nel problema di ottimizzazione (nel nostro caso, `liblinear`).\n* **`max_iter`**: Imposta il numero massimo di iterazioni affinché l'algoritmo di ottimizzazione converga e trovi i migliori parametri del modello.\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n#Importo LogisticRegression da scikit-learn\nfrom sklearn.linear_model import LogisticRegression\n\n#1. Instanzio il modello di Regressione Logistica\n# Durante la creazione dell' istanza imposto i parametri che desidero\nmodel = LogisticRegression(max_iter=100, solver='liblinear',C=1.0)\n\n#2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n#3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)\n\n```","metadata":{}},{"cell_type":"markdown","source":"### **Guida per la risoluzione**\n\nDi seguito sono spiegati i passaggi principali per la risoluzione dell' esercizio.\n\n1. **Creazione del modello:** Creare un' istanza della classe `LogisticRegression`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n    \n    - `max_iter` = 100\n    - `solver` = `'liblinear'`\n    - `C` = 1.0\n\n2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di train standardizzati. \n\n3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e test utilizzando il metodo `.predict()` del modello. \n\n4. **Valutazione delle prestazioni del modello:** Calcoliamo l' accuracy del modello. Ricordiamo che l' accuracy è data dal numero di predizioni corrette che il modello effettua rispetto al totale dei campioni. Dobbiamo valutare il modello sia sul validation set che sul test set. Infine stampare il valore di accuracy sul validation e sul test.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nimport numpy as np\n\n# Step 1 - Creazione del modello\n\n# svolgimento...\nmodel = LogisticRegression(solver='liblinear', max_iter=100, C=1.0)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:30:07.420337Z","iopub.execute_input":"2025-04-06T20:30:07.420758Z","iopub.status.idle":"2025-04-06T20:30:07.614614Z","shell.execute_reply.started":"2025-04-06T20:30:07.420726Z","shell.execute_reply":"2025-04-06T20:30:07.613486Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Step 2 - Addestramento del modello\n\n# svolgimento...\nmodel.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:30:12.984223Z","iopub.execute_input":"2025-04-06T20:30:12.984608Z","iopub.status.idle":"2025-04-06T20:30:13.002887Z","shell.execute_reply.started":"2025-04-06T20:30:12.984579Z","shell.execute_reply":"2025-04-06T20:30:13.001223Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-70acd6291fe8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# svolgimento...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"],"ename":"NameError","evalue":"name 'X_train_scaled' is not defined","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"# Step 3 - Calcolo delle predizioni\n\n# svolgimento...\npred_val = model.predict(X_val_scaled)\npred_test = model.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.260201Z","iopub.status.idle":"2025-04-06T20:28:28.260677Z","shell.execute_reply":"2025-04-06T20:28:28.260459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4 - Calcolo delle metriche di valutazione\n\n# svolgimento...\naccuracy_val = np.mean(pred_val == y_val)\naccuracy_test = np.mean(pred_test == y_test) \n\nprint(\"Accuracy sul validation set:\", accuracy_val)\nprint(\"Accuracy sul test set:\", accuracy_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.261709Z","iopub.status.idle":"2025-04-06T20:28:28.262172Z","shell.execute_reply":"2025-04-06T20:28:28.261977Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 2: Implementare Support Vector Machines (SVM)**\n\nPer implementare le SVM utilizziamo la classe `sklearn.svm.SVC` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n\nPer utilizzarla al meglio, di seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell' istanza:\n\n* **`C`**: Parametro di regolarizzazione. L'intensità della regolarizzazione è inversamente proporzionale a C.\n* **`kernel`**: Specifica il tipo di kernel da utilizzare nell'algoritmo (`'linear'`, `'poly'`, `'rbf'`).\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n#Importare la classe SVC da scikit-learn\nfrom sklearn.svm import SVC\n\n#1. Creare un' istanza della classe SVC\n# Durante la creazione dell' istanza imposto i parametri che desidero\nmodel = SVC(kernel='linear', C=1.0)\n\n#2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n#3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)","metadata":{}},{"cell_type":"markdown","source":"### **C** in SVM:\n\n**C** è una penalità per i punti classificati erroneamente.\n\n- **Small C**: Margine più ampio, tollera alcuni errori (rischio di underfitting).\n- **Large C**: Minimizza gli errori, margine più stretto (rischio di overfitting).","metadata":{}},{"cell_type":"markdown","source":"### **Guida per la risoluzione**\n\nDi seguito sono spiegati i passaggi principali per la risoluzione dell' esercizio.\n\n1. **Creazione del modello:** Creare un' istanza della classe `SVC`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n    \n    - `kernel` = `'linear'`\n    - `C` = 0.01\n\n2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di train standardizzati. \n\n3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e test utilizzando il metodo `.predict()` del modello. \n\n4. **Valutazione delle prestazioni del modello:** Calcoliamo l' accuracy del modello. Ricordiamo che l' accuracy è data dal numero di predizioni corrette che il modello effettua rispetto al totale dei campioni. Dobbiamo valutare il modello sia sul validation set che sul test set. Infine stampare il valore di accuracy sul validation e sul test.","metadata":{}},{"cell_type":"code","source":"# Step 1 - Creazione del modello\nfrom sklearn.svm import SVC\nimport numpy as np\n\n# svolgimento...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.263267Z","iopub.status.idle":"2025-04-06T20:28:28.263741Z","shell.execute_reply":"2025-04-06T20:28:28.263527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Addestramento del modello\n\n# svolgimento...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.264656Z","iopub.status.idle":"2025-04-06T20:28:28.265127Z","shell.execute_reply":"2025-04-06T20:28:28.264903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Calcolo delle predizioni\n\n# svolgimento...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.266168Z","iopub.status.idle":"2025-04-06T20:28:28.266782Z","shell.execute_reply":"2025-04-06T20:28:28.266532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4 - Calcolo delle metriche di valutazione\n\n# svolgimento...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.267824Z","iopub.status.idle":"2025-04-06T20:28:28.268308Z","shell.execute_reply":"2025-04-06T20:28:28.268112Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Esercizio 2.1: Implementare SVM con kernel trick**\n\nVogliamo implementare un classificatore SVM che utilizza il kernel-trick. Le linee guida sono esattamente quanto fatto prima, dobbiamo però modificare il tipo di kernel del modello. Per utilizzare il kernel trick usiamo un **kernel a base radiale (Radial Basis Function)** specificando il parametro:\n\n- `kernel` = `'rbf'`","metadata":{}},{"cell_type":"code","source":"# Step 1 - Creazione del modello\nfrom sklearn.svm import SVC\nimport numpy as np\n\n# svolgimento...\nsvm_rbf.fit(X_train_scaled, y_train)\n\n# Step 3 - Calcolo delle predizioni\n\n# svolgimento...\npred_val_rbf = svm_rbf.predict(X_val_scaled)\npred_test_rbf = svm_rbf.predict(X_test_scaled)\n\n# Step 4 - Calcolo delle metriche di valutazione\n\n# svolgimento...\naccuracy_val_rbf = np.mean(pred_val_rbf == y_val)\naccuracy_test_rbf = np.mean(pred_test_rbf == y_test)\n\nprint(\"Accuracy SVM RBF sul validation set:\", accuracy_val_rbf)\nprint(\"Accuracy SVM RBF sul test set:\", accuracy_test_rbf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.269284Z","iopub.status.idle":"2025-04-06T20:28:28.269788Z","shell.execute_reply":"2025-04-06T20:28:28.269560Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Esercizio 3: Metriche di valutazione**\n\n**Matrice di confusione:** \n\nLa matrice di confusione (anche nota come `confusion matrix` ) è una tabella che riassume le prestazioni di un modello di classificazione mostrando i conteggi dei veri positivi (TP), veri negativi (TN), falsi positivi (FP) e falsi negativi (FN). In questo codice, per un problema di classificazione binaria con classi 0 e 1, la `confusion matrix` è strutturata come segue:\n\n|                | **Predicted Class 0** | **Predicted Class 1** |\n|----------------|:------------------------:|:------------------------:|\n| **Actual Class 0** | TN                     | FP                     |\n| **Actual Class 1** | FN                     | TP                     |\n\n* **TN (True Negatives):** Il numero di istanze che erano effettivamente Classe 0 e sono state correttamente previste come Classe 0.\n\n* **FP (False Positives):** Il numero di istanze che erano effettivamente Classe 0 ma sono state erroneamente previste come Classe 1.\n\n* **FN (False Negatives):** Il numero di istanze che erano effettivamente Classe 1 ma sono state erroneamente previste come Classe 0.\n\n* **TP (True Positives):** Il numero di istanze che erano effettivamente Classe 1 e sono state correttamente previste come Classe 1.\n\n\n* **Accuracy:** Misura la correttezza complessiva del modello. È il rapporto tra le istanze correttamente classificate e il numero totale di istanze.\n\n    $$\n    \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n    $$\n\n* **Precision:** Misura l'accuratezza delle previsioni positive. È il rapporto tra le istanze positive correttamente previste e il numero totale di istanze previste come positive.\n\n    $$\\text{Precision} = \\frac{TP}{TP + FP}$$\n\n* **Recall (Sensitivity or True Positive Rate):** Misura la capacità del modello di trovare tutte le istanze positive. È il rapporto tra le istanze positive correttamente previste e il numero totale di vere istanze positive.\n\n    $$\\text{Recall} = \\frac{TP}{TP + FN}$$\n\n* **F1-Score:** La media armonica di precisione e richiamo. Fornisce un punteggio unico che bilancia sia la precisione che il richiamo, particolarmente utile quando c'è una distribuzione asimmetrica delle classi.\n\n    $$\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$","metadata":{}},{"cell_type":"markdown","source":"Per calcolare le metriche utilizziamo le funzioni presenti in `sklearn.metrics`:\n\n#### `confusion_matrix`\n\nDati in input il target reale e le predizioni calcola la matrice di confusione. Documentazione disponibile al seguente link [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).\n\n**Syntax**:\n```python\nconfusion_matrix(y_true, y_pred)\n```\n\n#### `classification_report`\n\nGenera un report testuale che mostra le principali metriche di classificazione. Documentazione disponibile al seguente link [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n\n**Syntax**:\n```python\nclassification_report(y_true, y_pred)\n```\n\n#### `precision_score`\n\nMisura il rapporto tra le istanze positive correttamente previste e il totale delle previsioni positive. Documentazione disponibile al seguente link [precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html).\n\n**Syntax**:\n```python\nprecision_score(y_true, y_pred, average='binary')\n```\n\n#### `recall_score`\n\nMisura il rapporto tra le istanze positive correttamente previste e il totale delle istanze positive effettive. Documentazione disponibile al seguente link [recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n\n**Syntax**:\n```python\nrecall_score(y_true, y_pred, average='binary')\n```\n\n#### `f1_score`\n\nCalcola la media armonica di precision e recall. Documentazione disponibile al seguente link [f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n\n**Syntax**:\n```python\nf1_score(y_true, y_pred, average='binary')\n```\n\n","metadata":{}},{"cell_type":"markdown","source":"### **Guida:**\n\n1. **Calcoliamo la matrice di confusione:** Calcolare la matrice di confusione con `confusion_matrix` e stamparla.\n\n2. **Calcoliamo precision, recall e F1 score:** Calcolare le metriche di valutazione con le funzioni presentate sopra e stamparle.\n\n3. **Calcoliamo il classification report:** Calcolare il classification report e stamparlo.\n\n4. **Stampare la matrice di confusione:** Utilizzare la funzione `plot_confusion_matrix` che vi abbiamo fornito per stampare la matrice di confusione. La funzione ha bisogno di un unico parametro che è la matrice di confusione calcolata al punto 1.","metadata":{}},{"cell_type":"code","source":"# Step 1 - Calcolare la matrice di confusione\n\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# svolgimento...\ncm = confusion_matrix(y_test, pred_test)\nprint(\"Matrice di Confusione:\")\nprint(cm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.270851Z","iopub.status.idle":"2025-04-06T20:28:28.271340Z","shell.execute_reply":"2025-04-06T20:28:28.271140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Calcolare precision, recall e F1 score\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# svolgimento...\nprecision = precision_score(y_test, pred_test, average='binary')\nrecall = recall_score(y_test, pred_test, average='binary')\nf1 = f1_score(y_test, pred_test, average='binary')\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.272483Z","iopub.status.idle":"2025-04-06T20:28:28.272895Z","shell.execute_reply":"2025-04-06T20:28:28.272744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Calcolare il report di classificazione\nfrom sklearn.metrics import classification_report\n\n# svolgimento...\nreport = classification_report(y_test, pred_test)\nprint(\"\\nClassification Report:\")\nprint(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.273900Z","iopub.status.idle":"2025-04-06T20:28:28.274259Z","shell.execute_reply":"2025-04-06T20:28:28.274131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4 - Visualizzare la matrice di confusione\n\ndef plot_confusion_matrix(cm):\n    \"\"\"\n    Visualizza una matrice di confusione come heatmap.\n    \n    Parameters:\n    -----------\n    cm : numpy.ndarray\n        La matrice di confusione da visualizzare\n    \"\"\"\n    plt.figure(figsize=(6, 4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n# svolgimento...\nplot_confusion_matrix(cm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.275580Z","iopub.status.idle":"2025-04-06T20:28:28.275873Z","shell.execute_reply":"2025-04-06T20:28:28.275754Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **ROC Curve, AUC**\n\nPer calcolare la ROC curve, e conseguentemente l' AUC, abbiamo bisogno delle probabilità di predizione. \n\nNel caso della **regressione logistica** possiamo utilizzare l' attributo del modello `predict_proba` da utilizzare come segue:\n\n```python\n# Estrai le probabilità della classe positiva\ny_pred_proba = classifier.predict_proba(X_test_scaled)[:, 1]\n```\n\nPer quanto riguarda invece l' **SVM**, è necessario specificare il parametro `probability` = **True** affinchè `predict_proba` funzioni.\n\n```python\n# Specifica il parametro probability=True \nclassifier = SVC(kernel='linear', C=0.01, probability=True)\n```\n\nUna volta estratte le probabilità possiamo utilizzare le funzione di `sklearn.metrics`:\n\n- `roc_curve` \n- `roc_auc_score`\n\nDi seguito è mostrata la sintassi per utilizzare le due funzioni.\n\n---\n\n#### `roc_curve`\n```python\n# Calcola i valori della curva ROC\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n```\nCalcola i valori della Curva ROC (Receiver Operating Characteristic): Tasso di Falsi Positivi (FPR), Tasso di Veri Positivi (TPR) e soglie.\n\n---\n\n#### `roc_auc_score`\n```python\n# Calcola AUC\nauc = roc_auc_score(y_test, y_pred_proba)\n```\nCalcola l'Area Under the Curve (AUC) per la ROC, quantificando la capacità del modello di distinguere tra classi positive e negative.","metadata":{}},{"cell_type":"code","source":"# Step 1 - Estrarre le probabilità dal modello di regressione logistica\n# ATTENZIONE: Per il calcolo della ROC curve ci servono le probabilità della classe positiva.\n\n# svolgimento...\ny_pred_proba_logistic = model.predict_proba(X_test_scaled)[:, 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.276659Z","iopub.status.idle":"2025-04-06T20:28:28.276984Z","shell.execute_reply":"2025-04-06T20:28:28.276829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Allenare l' SVM con il parametro probability=True ed estrarre le probabilità\n\n# svolgimento...\nsvm_model_prob = SVC(kernel='linear', C=0.01, probability=True, random_state=42)\nsvm_model_prob.fit(X_train_scaled, y_train)\ny_pred_proba_svm = svm_model_prob.predict_proba(X_test_scaled)[:, 1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.277968Z","iopub.status.idle":"2025-04-06T20:28:28.278307Z","shell.execute_reply":"2025-04-06T20:28:28.278184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Calcolare le curve ROC e AUC per entrambe le probabilità (logistic e SVM)\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n# svolgimento...\nfpr_logistic, tpr_logistic, thresholds_logistic = roc_curve(y_test, y_pred_proba_logistic)\nauc_logistic = roc_auc_score(y_test, y_pred_proba_logistic)\nprint(\"AUC - Regressione Logistica:\", auc_logistic)\n# Per il modello SVM\nfpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test, y_pred_proba_svm)\nauc_svm = roc_auc_score(y_test, y_pred_proba_svm)\nprint(\"AUC - SVM:\", auc_svm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.279074Z","iopub.status.idle":"2025-04-06T20:28:28.279387Z","shell.execute_reply":"2025-04-06T20:28:28.279253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 4 - Disegnare le curve ROC per entrambe le probabilità (logistic e SVM)\n\ndef plot_roc_curve(fpr, tpr, auc):\n    \"\"\"\n    Disegna la curva ROC e stampa il valore AUC.\n\n    Parameters:\n    -----------\n    fpr : array-like\n        Tasso di falsi positivi (False Positive Rate).\n    tpr : array-like\n        Tasso di veri positivi (True Positive Rate).\n    auc : float\n        Area sotto la curva (AUC).\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(6, 4))\n    plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {auc:.4f}')\n    plt.plot([0, 1], [0, 1], color='red', linestyle='--', lw=2)  # Linea di non discriminazione\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc='lower right')\n    plt.grid()\n    plt.show()\n\n    # Stampa il valore AUC\n    print(f\"AUC: {auc:.4f}\")\n\n# svolgimento...\nplot_roc_curve(fpr_logistic, tpr_logistic, auc_logistic)\nplot_roc_curve(fpr_svm, tpr_svm, auc_svm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.280058Z","iopub.status.idle":"2025-04-06T20:28:28.280374Z","shell.execute_reply":"2025-04-06T20:28:28.280244Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Esercizio 4: Classificazione multi classe**\n\nSe finora abbiamo lavorato soltanto con classificazione binaria, adesso addestriamo nuovamente i classificatori visti sopra, ma nella situazione in cui abbiamo più classi. ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n\nmnist = fetch_openml('mnist_784', version=1, parser='auto')\nX, y = np.array(mnist.data), np.array(mnist.target.astype(int))\n\n# Utilizziamo soltanto il 20% dei campioni del dataset per questioni di praticità\nn_percent = 0.2  \n\n# La funzione train_test_split ci assicura che i dati che rimuoviamo siano bilanciati.\n# In questo modo non alteriamo la distribuzione delle classi.\nX, _, y, _ = train_test_split(\n    X, y, train_size=n_percent, stratify=y, random_state=42\n)\n\nX, y = shuffle(X, y)\n\nprint(\"Shape of X:\", X.shape)\nprint(\"Shape of y:\", y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.281307Z","iopub.status.idle":"2025-04-06T20:28:28.281976Z","shell.execute_reply":"2025-04-06T20:28:28.281693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1 - Dividiamo il dataset in train, validation e test e standardizziamo.\ntrain_fraction = 0.6  \nvalidation_fraction = 0.2  \ntest_fraction = 0.2  \n\n\n# svolgimento...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.283359Z","iopub.status.idle":"2025-04-06T20:28:28.283713Z","shell.execute_reply":"2025-04-06T20:28:28.283580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2 - Alleniamo il modello di regressione logistica e calcoliamo le predizioni e prestazioni.\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\n# IMPORTANTE:\n# Quando istanziamo la classe LogisticRegression utilizziamo come parametri\n# max_iter=200 e solver='lbfgs'.\n\n# svolgimento...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.284559Z","iopub.status.idle":"2025-04-06T20:28:28.284853Z","shell.execute_reply":"2025-04-06T20:28:28.284735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3 - Alleniamo il modello di SVM e calcoliamo le predizioni e prestazioni.\nfrom sklearn.svm import SVC\n\n# IMPORTANTE:\n# Quando istanziamo la classe SVC utilizziamo come parametri C=0.01, \n# kernel='linear' e decision_function_shape='ovr'.\n\n# svolgimento...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.285568Z","iopub.status.idle":"2025-04-06T20:28:28.285880Z","shell.execute_reply":"2025-04-06T20:28:28.285754Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Esercizio 5: Scrivere una funzione pipeline per l' allenamento di un classificatore**\n\nLa funzione `pipeline` prende in input il train set, `X_train` e `y_train`, il validation set, `X_val` e `y_val`, e un dizionario `hyperparams` che contiene una configurazione di training.\n\nLa funzione deve:\n\n* Applicare la PCA **se richiesto**.\n\n* Standardizzare i dati **a prescindere che sia richiesto o meno**.\n\n* Allenare un classificatore. Il dizionario avrà una chiave `classifier`, il cui value può essere:\n\n    * `lr` per indicare un modello di **Regressione Logistica**.\n    * `svm` per indicare un modello **SVM**. \n\n* Effettuare le predizioni e utilizzarle per calcolare l' accuracy del classificatore.","metadata":{}},{"cell_type":"code","source":"# IMPORTANTE: Eseguire questa cella prima di procedere\n\ndef plot_confusion_matrix_multiclass(cm):\n    \"\"\"\n    Visualizza una matrice di confusione come heatmap.\n\n    Parameters:\n    -----------\n    cm : numpy.ndarray\n        La matrice di confusione da visualizzare\n    \"\"\"\n    # Calcola dinamicamente le etichette delle classi\n    class_labels = [f\"Class {i}\" for i in range(cm.shape[0])]\n    \n    # Visualizza la heatmap\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_labels, yticklabels=class_labels)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.286670Z","iopub.status.idle":"2025-04-06T20:28:28.287015Z","shell.execute_reply":"2025-04-06T20:28:28.286860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndef pipeline(X_train, y_train, X_val, y_val, hyperparams):\n    \n    if hyperparams['use_pca']:\n           # Implementare codice per Regressione Lineare\n        model = LogisticRegression(max_iter=200, solver='lbfgs', multi_class='auto')\n    elif hyperparams['classifier'] == 'svm':  \n        # Implementare codice per SVM\n        model = SVC(C=0.01, kernel='linear', decision_function_shape='ovr')\n    # Effettuare predizioni\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_val)\n    # Calcolare e stampare accuracy sul validation set \n    accuracy = np.mean(predictions == y_val)\n    print(f\"Accuracy sul validation set: {accuracy:.4f}\")\n    # Calcolare la matrice di confusione\n    cm = confusion_matrix(y_val, predictions)\n    print(\"Matrice di confusione:\")\n    print(cm)\n    # Visualizzare la matrice di confusione\n    plot_confusion_matrix_multiclass(cm)\n        \n       ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.287659Z","iopub.status.idle":"2025-04-06T20:28:28.287978Z","shell.execute_reply":"2025-04-06T20:28:28.287828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Provare la funzione pipeline su tutte le configurazioni presenti qui di seguito\n\nhyperparams_1 = {\n    'use_pca': False,  \n    'classifier': 'svm',  \n}\n\nhyperparams_2 = {\n    'use_pca': True,  \n    'classifier': 'svm',  \n}\n\nhyperparams_3 = {\n    'use_pca': False,  \n    'classifier': 'lr',  \n}\n\nhyperparams_4 = {\n    'use_pca': True,  \n    'classifier': 'lr',  \n}\n\n# svolgimento...\nprint(\"Configurazione 1:\")\npipeline(X_train, y_train, X_val, y_val, hyperparams_1)\n\nprint(\"\\nConfigurazione 2:\")\npipeline(X_train, y_train, X_val, y_val, hyperparams_2)\n\nprint(\"\\nConfigurazione 3:\")\npipeline(X_train, y_train, X_val, y_val, hyperparams_3)\n\nprint(\"\\nConfigurazione 4:\")\npipeline(X_train, y_train, X_val, y_val, hyperparams_4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T20:28:28.288757Z","iopub.status.idle":"2025-04-06T20:28:28.289081Z","shell.execute_reply":"2025-04-06T20:28:28.288953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}